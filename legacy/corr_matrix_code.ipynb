{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4988825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install yfinance pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e248ab",
   "metadata": {},
   "source": [
    "run all once.  \n",
    "last 2 cells produce the correlation matrices + print an example plot.  \n",
    "you only need to re-run the second to last cell if you want to change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e566f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "market_corr_pipeline.py\n",
    "\n",
    "Implements (paper-aligned) data loading + rolling correlation matrices:\n",
    "- log returns r_i(t) = log P_i(t) - log P_i(t-1)\n",
    "- epoch/window M = 40 days, shifted by step = 20 days (default)\n",
    "- \"stocks present for entire duration\": filter tickers by completeness\n",
    "- \"added zero return entries for missing days\": align to a common trading calendar\n",
    "  and fill missing RETURNS with 0.0\n",
    "\n",
    "Dependencies:\n",
    "    pip install yfinance pandas numpy\n",
    "\n",
    "Typical use:\n",
    "    python market_corr_pipeline.py --tickers tickers.csv --start 2000-01-01 --end 2024-12-31\n",
    "\n",
    "Or import functions in your project and call run_pipeline(...).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"yfinance is required. Install with: pip install yfinance\") from e\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PipelineConfig:\n",
    "    start: str = \"2000-01-01\"\n",
    "    end: str | None = None  # None = today\n",
    "    n_stocks_target: int = 200\n",
    "\n",
    "\n",
    "    window: int = 40\n",
    "    step: int = 20\n",
    "    max_missing_price_frac: float = 0.01\n",
    "\n",
    "    calendar_ticker: str = \"SPY\"\n",
    "\n",
    "    eps: float = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tickers \n",
    "def read_tickers(path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Reads tickers from:\n",
    "    - CSV with a column named 'ticker' or a single column\n",
    "    - TXT with one ticker per line\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "\n",
    "    if path.lower().endswith(\".txt\"):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            tickers = [line.strip() for line in f if line.strip()]\n",
    "        return _dedupe_clean_tickers(tickers)\n",
    "\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path)\n",
    "        if \"ticker\" in df.columns:\n",
    "            tickers = df[\"ticker\"].astype(str).tolist()\n",
    "        else:\n",
    "            # assume first column is tickers\n",
    "            tickers = df.iloc[:, 0].astype(str).tolist()\n",
    "        return _dedupe_clean_tickers(tickers)\n",
    "\n",
    "    raise ValueError(\"Ticker file must be .csv or .txt\")\n",
    "\n",
    "\n",
    "def _dedupe_clean_tickers(tickers: Iterable[str]) -> list[str]:\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for t in tickers:\n",
    "        t = t.strip().upper()\n",
    "        if not t or t in seen:\n",
    "            continue\n",
    "        seen.add(t)\n",
    "        out.append(t)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# Data\n",
    "def download_adjusted_close(\n",
    "    tickers: list[str],\n",
    "    start: str,\n",
    "    end: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads adjusted daily closes (auto_adjust=True) and returns a DataFrame:\n",
    "      index = dates, columns = tickers, values = adjusted close\n",
    "    \"\"\"\n",
    "    if len(tickers) == 0:\n",
    "        raise ValueError(\"No stocks provided.\")\n",
    "\n",
    "    data = yf.download(\n",
    "        tickers,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        auto_adjust=True,\n",
    "        progress=True,\n",
    "        group_by=\"column\",\n",
    "        threads=True,\n",
    "    )\n",
    "\n",
    "    # yfinance returns either:\n",
    "    # - MultiIndex columns (OHLCV x tickers) for multi-ticker\n",
    "    # - Single-index columns for single ticker\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        prices = data[\"Close\"].copy()\n",
    "    else:\n",
    "        # single ticker\n",
    "        prices = data[[\"Close\"]].copy()\n",
    "        prices.columns = tickers[:1]\n",
    "\n",
    "    prices = prices.sort_index()\n",
    "    return prices\n",
    "\n",
    "\n",
    "def get_trading_calendar_index(\n",
    "    start: str,\n",
    "    end: str | None,\n",
    "    calendar_ticker: str = \"SPY\",\n",
    ") -> pd.DatetimeIndex:\n",
    "    cal_prices = download_adjusted_close([calendar_ticker], start=start, end=end)\n",
    "    # keep only days where calendar ticker traded\n",
    "    idx = cal_prices.dropna().index\n",
    "    if len(idx) == 0:\n",
    "        raise RuntimeError(\"Could not build trading calendar index (calendar_ticker has no data).\")\n",
    "    return pd.DatetimeIndex(idx)\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "\n",
    "\n",
    "def filter_tickers_by_completeness(\n",
    "    prices: pd.DataFrame,\n",
    "    calendar_index: pd.DatetimeIndex,\n",
    "    max_missing_frac: float,\n",
    "    n_target: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - align prices to a common trading-day index\n",
    "    \"\"\"\n",
    "    aligned = prices.reindex(calendar_index)\n",
    "    missing_frac = aligned.isna().mean(axis=0)\n",
    "    good = missing_frac[missing_frac <= max_missing_frac].index.tolist()\n",
    "\n",
    "    if len(good) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No tickers passed completeness filtering. \"\n",
    "            \"Try increasing max_missing_price_frac or choosing a later start date.\"\n",
    "        )\n",
    "\n",
    "    aligned_good = aligned[good]\n",
    "\n",
    "    if aligned_good.shape[1] < n_target:\n",
    "\n",
    "        print(f\"[warn] Only {aligned_good.shape[1]} tickers passed filtering; target was {n_target}.\")\n",
    "        return aligned_good\n",
    "\n",
    "    return aligned_good.iloc[:, :n_target]\n",
    "\n",
    "\n",
    "def compute_log_returns_from_prices(\n",
    "    prices_aligned: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    r(t) = log(P(t)) - log(P(t-1))\n",
    "\n",
    "    Note: prices_aligned should already share a common calendar index.\n",
    "    \"\"\"\n",
    "    logp = np.log(prices_aligned)\n",
    "    rets = logp.diff()\n",
    "    return rets\n",
    "\n",
    "\n",
    "def fill_missing_returns_with_zero(\n",
    "    returns: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    return returns.fillna(0.0)\n",
    "\n",
    "\n",
    "def zscore_within_window(X: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Standardize each column (stock) within a window.\n",
    "    X: (L, N)\n",
    "    \"\"\"\n",
    "    mu = X.mean(axis=0, keepdims=True)\n",
    "    sd = X.std(axis=0, ddof=1, keepdims=True)\n",
    "    sd = np.maximum(sd, eps)\n",
    "    return (X - mu) / sd\n",
    "\n",
    "\n",
    "# correlation matrices\n",
    "\n",
    "def rolling_correlation_matrices(\n",
    "    returns: pd.DataFrame,\n",
    "    window: int,\n",
    "    step: int,\n",
    "    standardize_each_window: bool = True,\n",
    "    eps: float = 1e-12,\n",
    ") -> tuple[np.ndarray, pd.DatetimeIndex]:\n",
    "    \"\"\"\n",
    "    Computes rolling Pearson correlation matrices C(t) over returns.\n",
    "\n",
    "    returns: (T, N) DataFrame, index = dates\n",
    "    window: M (e.g., 40)\n",
    "    step: shift (e.g., 20)\n",
    "\n",
    "    Returns:\n",
    "      C_all: (K, N, N) float array\n",
    "      end_dates: length K (end date of each window)\n",
    "    \"\"\"\n",
    "    if window < 2:\n",
    "        raise ValueError(\"window must be >= 2\")\n",
    "    if step < 1:\n",
    "        raise ValueError(\"step must be >= 1\")\n",
    "\n",
    "    R = returns.to_numpy(dtype=float)\n",
    "    dates = returns.index\n",
    "    T, N = R.shape\n",
    "\n",
    "\n",
    "    mats: list[np.ndarray] = []\n",
    "    ends: list[pd.Timestamp] = []\n",
    "\n",
    "    # windows are [end-window, end)\n",
    "    for end in range(window, T + 1, step):\n",
    "        X = R[end - window:end, :]  # (window, N)\n",
    "\n",
    "        if standardize_each_window:\n",
    "            X = zscore_within_window(X, eps=eps)\n",
    "\n",
    "        C = np.corrcoef(X, rowvar=False)  # (N, N)\n",
    "\n",
    "        mats.append(C.astype(float, copy=False))\n",
    "        ends.append(dates[end - 1])\n",
    "\n",
    "    C_all = np.stack(mats, axis=0)\n",
    "    return C_all, pd.DatetimeIndex(ends)\n",
    "\n",
    "\n",
    "# pipeline\n",
    "def run_pipeline(\n",
    "    tickers: list[str],\n",
    "    cfg: PipelineConfig,\n",
    "    cache_dir: str | None = \"data_cache\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    End-to-end:\n",
    "      - download prices for tickers + calendar ticker\n",
    "      - build trading calendar index\n",
    "      - filter to ~200 stocks with near-complete history\n",
    "      - compute log returns\n",
    "      - fill missing returns with zeros (paper)\n",
    "      - compute rolling correlation matrices with window/step (paper)\n",
    "      - optionally save outputs\n",
    "\n",
    "    Returns a dict with:\n",
    "      prices, returns, corrs, end_dates, tickers_used\n",
    "    \"\"\"\n",
    "    os.makedirs(cache_dir, exist_ok=True) if cache_dir else None\n",
    "\n",
    "    # 1) calendar index\n",
    "    cal_idx = get_trading_calendar_index(cfg.start, cfg.end, calendar_ticker=cfg.calendar_ticker)\n",
    "\n",
    "    # 2) download prices for all candidate tickers\n",
    "    prices_raw = download_adjusted_close(tickers, start=cfg.start, end=cfg.end)\n",
    "\n",
    "    # 3) filter to those \"present\" (practical)\n",
    "    prices = filter_tickers_by_completeness(\n",
    "        prices_raw, cal_idx, max_missing_frac=cfg.max_missing_price_frac, n_target=cfg.n_stocks_target\n",
    "    )\n",
    "\n",
    "    tickers_used = list(prices.columns)\n",
    "\n",
    "    # 4) returns\n",
    "    rets = compute_log_returns_from_prices(prices)\n",
    "    rets = fill_missing_returns_with_zero(rets)\n",
    "\n",
    "    # 5) rolling correlations\n",
    "    corrs, end_dates = rolling_correlation_matrices(\n",
    "        rets, window=cfg.window, step=cfg.step, standardize_each_window=True, eps=cfg.eps\n",
    "    )\n",
    "\n",
    "    # 6) cache\n",
    "    if cache_dir:\n",
    "        prices.to_parquet(os.path.join(cache_dir, \"prices.parquet\"))\n",
    "        rets.to_parquet(os.path.join(cache_dir, \"returns.parquet\"))\n",
    "        np.save(os.path.join(cache_dir, \"corrs.npy\"), corrs)\n",
    "        end_dates.to_series().to_csv(os.path.join(cache_dir, \"corr_end_dates.csv\"), header=[\"end_date\"])\n",
    "        pd.Series(tickers_used, name=\"ticker\").to_csv(os.path.join(cache_dir, \"tickers_used.csv\"), index=False)\n",
    "\n",
    "    return {\n",
    "        \"prices\": prices,\n",
    "        \"returns\": rets,\n",
    "        \"corrs\": corrs,\n",
    "        \"end_dates\": end_dates,\n",
    "        \"tickers_used\": tickers_used,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfb582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using these for now, will add more later\n",
    "tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"META\", \"JPM\", \"JNJ\", \"XOM\", \"PG\", \"NVDA\"]\n",
    "\n",
    "cfg = PipelineConfig(\n",
    "    start=\"2000-01-01\",\n",
    "    end=\"2025-12-31\",\n",
    "    n_stocks_target=10,#will increase later\n",
    "    window=40,\n",
    "    step=20,\n",
    "    max_missing_price_frac=0.01,#set to 0 if you want target stocks exaclty\n",
    ")\n",
    "\n",
    "out = run_pipeline(tickers, cfg, cache_dir=None) \n",
    "\n",
    "print(\"Tickers used:\", len(out[\"tickers_used\"]))\n",
    "print(\"Corr shape:\", out[\"corrs\"].shape)\n",
    "print(\"First / last date:\", out[\"end_dates\"][0], out[\"end_dates\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#example on printing a matrix plot, dont keep in full code\n",
    "\n",
    "#d+1 goes forward one month\n",
    "#C_all is the array of matrices\n",
    "\n",
    "C_all = out[\"corrs\"]\n",
    "dates = out[\"end_dates\"]\n",
    "\n",
    "d = 20\n",
    "C = C_all[d]\n",
    "\n",
    "plt.imshow(C, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "plt.colorbar()\n",
    "plt.title(f\"Correlation matrix at {dates[d].date()}\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
